{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MarioGAN MUSIC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpiuw3WLYEYDC5EYfp9i3O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nirav1221/MarioMusicGan/blob/master/MarioGAN_MUSIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UScp2ClXFpG",
        "colab_type": "text"
      },
      "source": [
        "#Generating Mario Themed music with python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nTh9-_8XO5d",
        "colab_type": "text"
      },
      "source": [
        "Instructions\n",
        "- Change the Runtime type and select **Hardware accelerator** to **GPU**\n",
        "- Run all the cells in given order\n",
        "- Output will be generated with name\n",
        "  ***gan_final.mid***\n",
        "- Double Click to download file.\n",
        "- While training,you can change the **epochs** parameter.\n",
        "- Optional\n",
        "  - Upload listfile.data\n",
        "  - Upload descriminator and generator weights and model\n",
        "  - File Names:\n",
        "   - Descriminator Model: disc.h5\n",
        "   - Generator Model: gen.h5\n",
        "   - Descriminator Weights: dw.h5\n",
        "   - Generator Weights: gw.h5\n",
        "\n",
        "Note Directory can be located at\n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QABN8pGmFAlc",
        "colab_type": "code",
        "outputId": "a09faa15-d217-4296-a3bf-5350d866b113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.argv[0]\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow-gpu==1.14.0\n",
        "#!pip install tensorflow-gpu==1.14.0\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.2.0rc2:\n",
            "  Successfully uninstalled tensorflow-2.2.0rc2\n",
            "Collecting tensorflow-gpu==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 31kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.27.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (3.10.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 41.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.34.2)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 60.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14.0) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.10.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTZPQmBEFGMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import glob\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "from keras.layers import Input, Dense, Reshape, Dropout, CuDNNLSTM, Bidirectional\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "def get_notes():\n",
        "    \"\"\" Get all the notes and chords from the midi files \"\"\"\n",
        "    notes = []\n",
        "\n",
        "    for file in glob.glob(\"MIDIs/*.mid\"):\n",
        "        try:\n",
        "          midi = converter.parse(file)\n",
        "\n",
        "          print(\"Parsing %s\" % file)\n",
        "\n",
        "          notes_to_parse = None\n",
        "\n",
        "          try: # file has instrument parts\n",
        "              s2 = instrument.partitionByInstrument(midi)\n",
        "              notes_to_parse = s2.parts[0].recurse() \n",
        "          except: # file has notes in a flat structure\n",
        "            \n",
        "              notes_to_parse = midi.flat.notes\n",
        "              \n",
        "          for element in notes_to_parse:\n",
        "              if isinstance(element, note.Note):\n",
        "                  notes.append(str(element.pitch))\n",
        "              elif isinstance(element, chord.Chord):\n",
        "                  notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "        except Exception as e:\n",
        "          continue\n",
        "\n",
        "    return notes\n",
        "\n",
        "def prepare_sequences(notes, n_vocab):\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    sequence_length = 100\n",
        "\n",
        "    # Get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "    # Create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # Reshape the input into a format compatible with LSTM layers\n",
        "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    \n",
        "    # Normalize input between -1 and 1\n",
        "    network_input = (network_input - float(n_vocab)/2) / (float(n_vocab)/2)\n",
        "    network_output = np_utils.to_categorical(network_output)\n",
        "\n",
        "    return (network_input, network_output)\n",
        "\n",
        "def generate_notes(model, network_input, n_vocab):\n",
        "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "    # pick a random sequence from the input as a starting point for the prediction\n",
        "    start = numpy.random.randint(0, len(network_input)-1)\n",
        "    \n",
        "    # Get pitch names and store in a dictionary\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    # generate 500 notes\n",
        "    for note_index in range(500):\n",
        "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "        index = numpy.argmax(prediction)\n",
        "        result = int_to_note[index]\n",
        "        prediction_output.append(result)\n",
        "        \n",
        "        pattern = numpy.append(pattern,index)\n",
        "        #pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    return prediction_output\n",
        "  \n",
        "def create_midi(prediction_output, filename):\n",
        "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
        "        from the notes \"\"\"\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for item in prediction_output:\n",
        "        pattern = item[0]\n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(int(current_note))\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp='{}.mid'.format(filename))\n",
        "\n",
        "class GAN():\n",
        "    def __init__(self, rows):\n",
        "        self.seq_length = rows\n",
        "        self.seq_shape = (self.seq_length, 1)\n",
        "        self.latent_dim = 1000\n",
        "        self.disc_loss = []\n",
        "        self.gen_loss =[]\n",
        "        \n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        # Build and compile the discriminator\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "        # Build the generator\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        # The generator takes noise as input and generates note sequences\n",
        "        z = Input(shape=(self.latent_dim,))\n",
        "        generated_seq = self.generator(z)\n",
        "\n",
        "        # For the combined model we will only train the generator\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        # The discriminator takes generated images as input and determines validity\n",
        "        validity = self.discriminator(generated_seq)\n",
        "\n",
        "        # The combined model  (stacked generator and discriminator)\n",
        "        # Trains the generator to fool the discriminator\n",
        "        self.combined = Model(z, validity)\n",
        "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "        if(os.path.exists(\"disc.h5\")):\n",
        "          print(\"Found Discriminator Model\")\n",
        "          return load_model('disc.h5')\n",
        "        model = Sequential()\n",
        "        model.add(CuDNNLSTM(512, input_shape=self.seq_shape, return_sequences=True))\n",
        "        model.add(Bidirectional(CuDNNLSTM(512)))\n",
        "        model.add(Dense(512))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dense(256))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.summary()\n",
        "\n",
        "        seq = Input(shape=self.seq_shape)\n",
        "        validity = model(seq)\n",
        "\n",
        "        return Model(seq, validity)\n",
        "      \n",
        "    def build_generator(self):\n",
        "        if(os.path.exists(\"gen.h5\")):\n",
        "          print(\"Found Generator Model\")\n",
        "          return load_model('gen.h5')\n",
        "        model = Sequential()\n",
        "        model.add(Dense(256, input_dim=self.latent_dim))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dense(512))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dense(1024))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dense(np.prod(self.seq_shape), activation='tanh'))\n",
        "        model.add(Reshape(self.seq_shape))\n",
        "        model.summary()\n",
        "        \n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        seq = model(noise)\n",
        "\n",
        "        return Model(noise, seq)\n",
        "\n",
        "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
        "\n",
        "        # Load and convert the data\n",
        "        if not os.path.exists('listfile.data'):\n",
        "          print('Extracting notes from midi')\n",
        "          notes = get_notes()\n",
        "          with open('listfile.data', 'wb') as filehandle:\n",
        "            pickle.dump(notes, filehandle)\n",
        "        else:\n",
        "          with open('listfile.data', 'rb') as filehandle:\n",
        "            notes = pickle.load(filehandle)\n",
        "          print('Loading notes from file.')\n",
        "        #notes = get_notes()\n",
        "        #print('notes type : ',type(notes),notes)\n",
        "        \n",
        "        n_vocab = len(set(notes))\n",
        "        X_train, y_train = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        real = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "        \n",
        "        # Training the model\n",
        "        for epoch in range(epochs):\n",
        "            if(os.path.exists(\"dw.h5\") and os.path.exists(\"gw.h5\")  ):\n",
        "              self.discriminator.load_weights(\"dw.h5\")\n",
        "              self.generator.load_weights(\"gw.h5\")\n",
        "              break\n",
        "            # Training the discriminator\n",
        "            # Select a random batch of note sequences\n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            real_seqs = X_train[idx]\n",
        "\n",
        "            #noise = np.random.choice(range(484), (batch_size, self.latent_dim))\n",
        "            #noise = (noise-242)/242\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "\n",
        "            # Generate a batch of new note sequences\n",
        "            gen_seqs = self.generator.predict(noise)\n",
        "\n",
        "            # Train the discriminator\n",
        "            \n",
        "            d_loss_real = self.discriminator.train_on_batch(real_seqs, real)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_seqs, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "            \n",
        "\n",
        "            #  Training the Generator\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "\n",
        "            # Train the generator (to have the discriminator label samples as real)\n",
        "            g_loss = self.combined.train_on_batch(noise, real)\n",
        "\n",
        "            # Print the progress and save into loss lists\n",
        "            if epoch % sample_interval == 0:\n",
        "              print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "              self.disc_loss.append(d_loss[0])\n",
        "              self.gen_loss.append(g_loss)\n",
        "        else:\n",
        "          self.discriminator.save_weights(\"dw.h5\")\n",
        "          self.generator.save_weights(\"gw.h5\")\n",
        "          self.discriminator.save(\"disc.h5\")\n",
        "          self.generator.save('gen.h5')\n",
        "        '''\n",
        "        if not (os.path.exists('Out')):\n",
        "            os.mkdir('Out')\n",
        "            os.chdir('Out')\n",
        "        '''\n",
        "        self.generate(notes)\n",
        "        self.plot_loss()\n",
        "        \n",
        "    def generate(self, input_notes):\n",
        "        # Get pitch names and store in a dictionary\n",
        "        notes = input_notes\n",
        "        pitchnames = sorted(set(item for item in notes))\n",
        "        int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "        \n",
        "        # Use random noise to generate sequences\n",
        "        noise = np.random.normal(0, 1, (1, self.latent_dim))\n",
        "        predictions = self.generator.predict(noise)\n",
        "        print(int_to_note)\n",
        "\n",
        "        pred_notes = [x*242 + 242 for x in predictions[0]]\n",
        "        print([int(x) for x in pred_notes])\n",
        "        #pred_notes = [int_to_note[int(x)] for x in pred_notes]\n",
        "        pred_notes1=[]\n",
        "        for x in pred_notes:\n",
        "          try:\n",
        "            pred_notes1.append(int_to_note[int(x)])\n",
        "          except KeyError:\n",
        "            continue  \n",
        "        create_midi(pred_notes1, out)\n",
        "        \n",
        "    def plot_loss(self):\n",
        "        plt.plot(self.disc_loss, c='red')\n",
        "        plt.plot(self.gen_loss, c='blue')\n",
        "        plt.title(\"GAN Loss per Epoch\")\n",
        "        plt.legend(['Discriminator', 'Generator'])\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.savefig('GAN_Loss_per_Epoch_final.png', transparent=True)\n",
        "        plt.close()\n",
        "#dir [out]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  #print(os.pwd())\n",
        "  \n",
        "  #k=os.getcwd()\n",
        "  #print(k)\n",
        "  try:\n",
        "    gan = GAN(rows=100)    \n",
        "    '''\n",
        "    pwd = sys.argv[1]\n",
        "    os.chdir(pwd)\n",
        "    if len(sys.argv) == 3:\n",
        "      out = sys.argv[2]\n",
        "    else:\n",
        "      out='gan_final'\n",
        "    '''\n",
        "    out='gan_final'\n",
        "    gan.train(epochs=10000, batch_size=32, sample_interval=1)\n",
        "  except Exception as e:\n",
        "    raise e\n",
        "    print('Error\\n',e)\n",
        "  #finally:\n",
        "    #os.chdir(k)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}